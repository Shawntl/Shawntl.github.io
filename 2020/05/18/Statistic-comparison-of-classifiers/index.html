<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Statistic Inference," />










<meta name="description" content="写作背景最近工作中接到要评价多个机器学习分类器性能的任务。不知道在互联网这样的行业是否会有严格进行多个分类器进行比较的必要？但这件事在学术界还是有相对完整的一套体系的。而在生物医药这样的行业，私以为严谨就显得更加重要。我就在本文中大致分享一下： 有了实验评估方法和性能度量，看起来就能对学习器的性能进行评估比较了：先使用某种实验评估方法测得学习器的某个性能度量结果， 然后对这些结果进行比较。但怎么来">
<meta property="og:type" content="article">
<meta property="og:title" content="Statistical Comparisons of Classifiers">
<meta property="og:url" content="http://yoursite.com/2020/05/18/Statistic-comparison-of-classifiers/index.html">
<meta property="og:site_name" content="Shawn&#39;s Blog">
<meta property="og:description" content="写作背景最近工作中接到要评价多个机器学习分类器性能的任务。不知道在互联网这样的行业是否会有严格进行多个分类器进行比较的必要？但这件事在学术界还是有相对完整的一套体系的。而在生物医药这样的行业，私以为严谨就显得更加重要。我就在本文中大致分享一下： 有了实验评估方法和性能度量，看起来就能对学习器的性能进行评估比较了：先使用某种实验评估方法测得学习器的某个性能度量结果， 然后对这些结果进行比较。但怎么来">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://i2.tiimg.com/711106/4870957db45724e6.png">
<meta property="og:image" content="http://i2.tiimg.com/711106/34507a98ab89a839.png">
<meta property="og:image" content="http://i2.tiimg.com/711106/4b1014e31ae29278.png">
<meta property="og:image" content="http://i1.fuimg.com/711106/07eba0f63f0978db.png">
<meta property="og:image" content="http://i2.tiimg.com/711106/4a91dfbd837638b9.png">
<meta property="og:image" content="http://i2.tiimg.com/711106/cdb90d693cb3fc3b.png">
<meta property="og:image" content="http://i2.tiimg.com/711106/940d7aa866cc083d.png">
<meta property="article:published_time" content="2020-05-18T01:54:51.000Z">
<meta property="article:modified_time" content="2020-06-03T06:30:22.397Z">
<meta property="article:author" content="Shawn_Song">
<meta property="article:tag" content="Statistic Inference">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://i2.tiimg.com/711106/4870957db45724e6.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/05/18/Statistic-comparison-of-classifiers/"/>





  <title>Statistical Comparisons of Classifiers | Shawn's Blog</title>
  








<meta name="generator" content="Hexo 4.2.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Shawn's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Talk is cheap, Show me the data</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-edit"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-clone"></i> <br />
            
            Categories
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/18/Statistic-comparison-of-classifiers/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shawn_Song">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://www.qqtouxiang.com/d/file/tupian/mx/20170713/jitdbe00jpfpd.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Shawn's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Statistical Comparisons of Classifiers</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-05-18T09:54:51+08:00">
                2020-05-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Statistics/" itemprop="url" rel="index">
                    <span itemprop="name">Statistics</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="写作背景"><a href="#写作背景" class="headerlink" title="写作背景"></a>写作背景</h1><p>最近工作中接到要评价多个机器学习分类器性能的任务。不知道在互联网这样的行业是否会有严格进行多个分类器进行比较的必要？但这件事在学术界还是有相对完整的一套体系的。而在生物医药这样的行业，私以为严谨就显得更加重要。我就在本文中大致分享一下：</p>
<p>有了实验评估方法和性能度量，看起来就能对学习器的性能进行评估比较了：先使用某种实验评估方法测得学习器的某个性能度量结果， 然后对这些结果进行比较。但怎么来做这个比较呢？是直接取得性能度量的值然后“比较大小”吗？实际上，机器学习中性能比较这件事比大家想象的复杂得多，这里面涉及几个重要因素：首先， 我们希望比较的是泛化性能，然而通过实验评估方法我们获得的是测试集上的性能，两者的对比结果可能未必相同；第二， 测试集上的性能与测试集本身的选择有很大关系，且不论使用不同大小的测试集会得到不同的结果，即便用相同大小的测试集，若包含的测试集样例不同，测试结果也会不同；第三，很多机器学习算法本身有一定的随机性，即便用相同的参数设置在同一个测试集上多次运行，其结果也会有不同。那么有没有适当的方法对学习器性能进行比较呢？</p>
<p>统计假设检验（hypothesis test)为我们进行学习器性能比较提供了重要依据。显著性检验是统计学里的工具，被广泛应用到社会科学，心理学，经济学等很多学科中的研究中，当然也包括计算机科学，平常看论文偶尔也会遇到假设检验。</p>
<p>但必须承认的是，这几年，无论是CV、NLP还是数据挖掘，大部分论文里面都鲜有做假设检验的。绝大多数情况下，作者都只会给出对比实验的结果，根据研究的问题会涉及到3～10个数据集不等，如果在所有数据集上都能优于之前的SOTA, 那就claim自己的算法/模型更优。顶会的oral甚至最佳论文亦是如此。</p>
<p>那为什么有人会觉得不做显著性检验不行呢？在这篇笔记里，我尝试去剖析这个问题，看法未必都对，欢迎有不同见解的人交流。</p>
<p>这篇文章的大纲如下：</p>
<ol>
<li>假设检验的基石 —— 中心极限定理</li>
<li>假设检验的流程</li>
<li>机器学习中的假设检验 —— 分享Demsar 06年那篇经典论文</li>
<li>假设检验的局限</li>
</ol>
<p>这里我会重点讨论第三部分，默认读这篇文章的人都是有一定统计学基础的。</p>
<h1 id="中心极限定理"><a href="#中心极限定理" class="headerlink" title="中心极限定理"></a>中心极限定理</h1><p>中心极限定理是概率论里很重要的一个定理，因为它使得很多建立在正态分布上的概率方法和统计方法可以被应用到涉及到别的分布形式的问题上。</p>
<p>经典中心极限定理描述的是：</p>
<blockquote>
<p><font color=gray size=3>如果我们从同一个总体分布中独立采样出一组数据，这组数据的均值是一个随机变量，它服从于一个以总体均值为均值，标准差等于总体标准差除以样本大小的平方根的正态分布。</font></p>
</blockquote>
<p>也可以描述为：</p>
<blockquote>
<p><font color=gray size=3> <strong>Lindeberg-Levy CLT.</strong> Suppose {X<sub>1</sub>, X<sub>2</sub>, ….} is a sequence of i.i.d random variables with E[X<sub>i</sub>]=$\mu$ and Var[X<sub>i</sub>]=$\sigma$^2 &lt;$\infty$. Then as n approaches infinity, the random variables $\sqrt{n}$(S<sub>n</sub>-$\mu$) converge in distribution to a normal N(0, $\sigma$^2 ) :</p>
<center>$\sqrt{n}$(S<sub>n</sub>-$\mu$) &rarr; N(0, $\sigma$^2 )</center> 
</font>
</blockquote>
<p>变换一下其实是一样的。它的特别之处就在于我们<strong>并不要求总体分布必须是正态分布。</strong></p>
<h1 id="假设检验的流程"><a href="#假设检验的流程" class="headerlink" title="假设检验的流程"></a>假设检验的流程</h1><p>##统计学的分类<br>统计学是一门系统的学科，建立在17世纪发展的概率论之上，可以分为<strong>数理统计学</strong>和<strong>应用统计学</strong>两大派系。其中应用统计学又可以细分为以描述数据为目的的<strong>描述统计学（descriptive statistics）</strong>和以从数据中获取结论为目的的<strong>推断统计学（inferential statistics）。</strong>机器学习最开始严格来说并不是一个学科，但在不断发展的过程中，从各个学科包括统计里吸纳了很多概念、工具和方法， 集百家之长，逐渐形成了自己的体系。机器学习并不是简单地统计的延伸，但它用到了很多统计里的概念、方法和工具，假设检验就是其中一个重要工具。</p>
<h2 id="假设检验的流程可以归纳如下："><a href="#假设检验的流程可以归纳如下：" class="headerlink" title="假设检验的流程可以归纳如下："></a>假设检验的流程可以归纳如下：</h2><p><strong>STEP0</strong>: 进行试验， 得到一组/两组数据。我们可能会对数据的均值/比例/方差感兴趣；<br><strong>STEP1</strong>: 分析问题，建立零假设和备择假设。（emm..这一步在我看来是最重要的一步，因为这需要讲一个业务决策问题转化match成统计问题，非常考验数据科学家的敏感度和经验。） 根据假设可确定要进行<strong>双尾检验（two-tailed test）</strong>还是<strong>单尾检验（One-tailed test）。</strong>若检验目的是判断XX与XX是否不同，那就用双尾检验。若检验目的是判断XX是否优于/大于XX, 那就用单尾检验;<br><strong>STEP2</strong>：根据数据的量和性质选择合适的检验方法以及合适的检验统计量，若检验目的是判断样本均值和某个特定值（一般是认为给定，比如股票55%的预期历史收益率）是否不同，那就是单样本检验；若检验目的是判断两个样本均值是否不同，则是双样本检验。对于双样本检验，若计算出两个样本集均值的两组数据是成对（关联）的就用成对检验（paired-test）,否则就用独立检验。什么叫成对呢？比如我在另一篇关于因果推断的博文中提到的，在接受干预变量前后的观察结果{Y<sub>1</sub>,Y<sub>0</sub>}就是一组成对数据，当时我们的做法是两两做差，计算差值的平均值，当作统计量。独立检验则是先分别计算两组样本的均值再做差当作统计量。常见检验方法如下：</p>
<div align=center><img width="450" height="250" src="http://i2.tiimg.com/711106/4870957db45724e6.png"/></div>   
特别地， 非参数检验也很流行，这类检验方法不需要假设数据所服从的分布，是我这篇文章所在场景介绍的重点。  
**STEP3**:设定一个显著水平$\alpha$, 一般取作5%或者1%，但是实际很多应用场景，使用工具的人并不是专业的统计学家，要求他们拍脑袋随便拍一个显著水平似乎也不是很合适，所以我们一般使用p-value去比较科学家心中的那个特定场景下的显著水平。  
**STEP4**： 计算（标准化）检验统计量T, 分为z-value 和t-value两种，计算方式一般都是：
$$\frac{\overline{x}-\mu_0}{\sigma/\sqrt{n}}
\tag{2.1}$$  
当总体标准差$\sigma$已知时，计算z-value;反之，用样本标准差s代替$\sigma$, 计算出t-value.检验比例/方差时会有一些不同。  
**STEP5**: 有两种做法  
* 查表，不同的检验方法在查表时也不同，比如z-test是查标准正态分布表，而其他test则一般是查临界值表。如果是临界值表，就可以直接判断出观测值是否落在拒绝域中；如果是标准正态分布表，那查表结果可以用来计算p值；
* 计算p-value, 有些情况下可以直接根据观测值计算出p-value；  

<p><strong>STEP6</strong>：得出结论  </p>
<ul>
<li>如果观测值落在拒绝域上，拒绝零假设，接受备择假设。</li>
<li>如果p-value  小于设定的显著水平$\alpha$, 拒绝零假设，接受备择假设。</li>
</ul>
<p><strong>注意</strong>：计算标准化统计量时分母是$\sigma/\sqrt{n}$而不是$\sigma$,这是因为我们要标准化的是统计量T而不是数据X。比如要检验均值，那么统计量就是样本均值X bar, 把它视作一个随机变量。$\mu_0$和$\sigma$是总体分布的参数，是针对随机变量X而言的。根据中心极限定理，可以得出X bar 服从一个正态分布，其均值等于总体分布的均值$\mu_0$， 标准差则等于总体分布的标准差除以样本大小的平方根。直觉上，如果n&rarr;$\infty$，那么样本均值也会趋向于总体均值，偏差会越来越小了。从这里也可以得出，样本量越大，使用统计推断出的统计量不确定性越低，反之，则越高。<br>#机器学习中的假设检验<br>一般来说，假设检验在机器学习中最常见的用法有：</p>
<ul>
<li>分析线性回归的某个参数是否显著为0，若是就说明对应的输入特征对模型影响不大。</li>
<li>分析引入某个因素后是否会改变事物的性质/结果。比如A/B test以及我介绍过的因果推断中，干预变量对观察结果的影响是否显著。<br>这类假设检验都是以<strong>分析数据推断出知识</strong>为目的，只有一个固定模型或者干脆就没有模型。</li>
</ul>
<p>但是在这篇文章中，我们主要是以比较模型为目的。我们用假设检验是为了比较不同模型在数据集上的效果，比如模型A是否明显优于模型B。因为两个模型在同一个测试集上进行评估，所以会得到两组成对的数据，做成对检验合适。不过做Paired t-test, 其实我们是假设了测试集样本大小足够大时，两个模型效果的差距服从正态分布。如果我们不想假设分布形式，可以用non-parametric的检验方法。一般情况我们得出的结论是模型A是否在XXX数据集上优于模型B。而如果我们希望判断模型A是否在所有数据集上一致优于模型B，那又有点不一样。我们下面要分享的这篇论文^[1] 就是应用于这样的场景的。<br>一般而言我们衡量两个或者多个算法在单个数据集上的表现方法是很成熟的，而且如果数据量足够大能够代表总体，这样实验得出的结论也比较可信的。但是有些时候我无法得到可以代表总体的大样本，那我们就只能尽可能收集一个大类问题下的多个小样本，从多个小样本的表现中推断总体表现。这时候的问题就变成对比两个或多个算法在多个数据集上的表现。<br>首先结论如下，在对比<strong>两个算法</strong>在<strong>多个数据集</strong>上的表现时：  </p>
<ul>
<li>如果样本配对（paired）且符合正态分布，优先使用配对t检（paired t test）。注意这里的样本是一个数据集。</li>
<li>如果样本不符合正态分布，但符合配对，使用Wilcoxon Signed Ranks test。</li>
<li>如果样本既不符合正态分布，也不符合配对，甚至样本量都不一样大，可以尝试Mann Whitney U test。 值得注意的是，MW是用来处理独立测量（independent measures）数据，要分情况讨论，后文会深入分析。</li>
</ul>
<p>在对比<strong>多个算法</strong>在<strong>多个数据集</strong>上的表现时：</p>
<ul>
<li>如果样本符合ANOVA的假设（如正态分布、等方差），优先使用ANOVA。</li>
<li>如果样本不符合ANOVA的假设，使用Friedman test配合Nemenyi test做post-hoc。</li>
<li>如果两个算法测试的样本量不一样，或因为特定原因不能使用Friedman-Nemenyi, 可以尝试Kruskal Wallis配合Dunn’s test。值得注意的是，这种方法是用来处理独立测量数据，要分情况讨论。</li>
</ul>
<h2 id="1-为什么需要对比算法性能？"><a href="#1-为什么需要对比算法性能？" class="headerlink" title="1. 为什么需要对比算法性能？"></a>1. 为什么需要对比算法性能？</h2><p>统计学家George Box说过：“All models are wrong, but some are useful”. 通俗来讲，<strong>任何算法都有局限性，所以不存在“通用最优算法”，只有在特定情境下某种算法可能是渐进最优的。</strong><br>因此，评估算法性能并选择最优算法是非常重要的。不幸的是，统计学评估还没有在机器学习领域普及，很多评估往往是在一个数据集上的简单分析，因此证明效果有限。  </p>
<h2 id="2-评估算法中的陷阱"><a href="#2-评估算法中的陷阱" class="headerlink" title="2. 评估算法中的陷阱"></a>2. 评估算法中的陷阱</h2><p>首先我们常说的是要选择一个<strong>正确的评估标准</strong>，常见的有：准确率（accuracy）、召回率（recall）、精确率（precision）、ROC、PR-curve、F1等。这方面知识比较容易理解，很多科普书都有介绍，我就不赘述了。<br>其次我们要正确理解测量方法，常见的有：</p>
<ul>
<li>独立测量（independent measures）:不同样本的观测对象是独立的，不存在关联。</li>
<li>重复测量（repeated measures）:样本中使用的观测对象是相同的，仅仅是独立变量在上面的作用结果不同。</li>
<li>以及成对测量（matched pair）：不同样本中采用不同的观测对象，但尽量使得样本间的观测对象成对相似。</li>
</ul>
<p>举个例子，我们想要分析刷抖音时间（每天3小时 vs. 每天10小时）对于大学生成绩的影响。如果我们使用相同的20个学生，观察他们每天3小时和10小时的区别，那就是重复测量。如果我们选择·40个学生，分成两组每组20人，再分别观察那就是独立测量。如果我们先找20个学生，再找20个和他们非常相似的大学生，并配对观察，就是成对相似。<br><strong>我们发现，当错误地理解测量方式时，就无法使用正确的统计手段进行分析。</strong><br>在这篇文章中我们默认：评估不同算法在多个相同数据集上的表现属于重复测量。  同时，本文介绍的方法可以用于对比任何评估标准。  </p>
<h2 id="3-两种算法间的比较：-不恰当方法"><a href="#3-两种算法间的比较：-不恰当方法" class="headerlink" title="3. 两种算法间的比较： 不恰当方法"></a>3. 两种算法间的比较： 不恰当方法</h2><div align=center><img width="250" height="250" src="http://i2.tiimg.com/711106/34507a98ab89a839.png"/></div>   
上图展示了两种决策树方法（C4.5, C4.5+m）在14个数据集上的准确率。那么该如何对比两种算法呢？先说几种错误（不恰当）的方法：  
**不恰当方法1:求每个算法在所有数据集上的均值，并比较大小。** 错误原因： a. 不同领域或者说不同体系的数据集上的误差期望是不相同的，平均不同数据集上的误差是没有意义的。数据不符合相称性（commensurate）。b. 平均这个操作对离群点非常敏感，它会让在某个数据集上表现非常好的算法结果掩盖了表现不好的数据集，或者相反，在某个数据集上表现很差可能会导致决策者判断在所有数据集上表现都不好。  
**不恰当方法2：进行配对样本t检验（Paired t test）。**显然，t test是统计学方法，可以用来查看两个算法在每个数据上的平均差值是否不等于0。但这个方法不合适原因有几点：
* 和平均一样，要求样本符合正态分布，显然我们无法保证不同数据集上的准确率符合正态分布。
* t-test对样本的大小有一定的要求，一般最低需要>30个样本。在这个例子中我们只有14个，且大部分情况下我们没有30个数据集来做实验。
* 因为缺乏相称性，统计结果易受到异常值影响（outliers）  

<p><strong>不恰当方法3：符号检验（sign test）</strong>是一种无参数（non-parametric)的检验，优点是对于样本分布没有要求，不要求正态性。比较方法很简单，就是在每个数据集上看哪个算法更好，之后统计每个算法占优的数据集总数。这也是一般人做比较符合直觉的一种不太专业的方法。以这个例子为例，C4.5在两个数据集上最优，2个平手，10个最差。这个时候我们就得出结论未免有些草率，我们还需要对这个结果计算置信区间，发现p&lt;0.05需要至少在11个数据集上表现最优。因此这个方法的缺点有：  </p>
<ul>
<li>符号检验是一种非常弱的检验方法，仅对比优劣损失了大量信息，失去了定量信息（quantitative）,比如优劣比8:6和13:1的意义是一样的。正因为如此，临界值（critical value)一般都需要很大，比如这个例子中的$\alpha$=0.05的临界值是11。  </li>
<li>另一个问题是，因为缺乏定量信息，很多时候很难确定“优胜”是否来自随机性。举个例子，0.99&lt;0.991是否真的代表算法A更好？ 一种看法是需要定义一个阈值，仅当差别大于阈值才能说明更好。然而这种看法的问题在于，假设算法A在1000个数据集上都以“微弱优势”胜过了B，那么我们是否需要怀疑显著性？因此，<strong>根本问题还是，符号检验需要大样本量才能得出显著性。</strong>   </li>
</ul>
<div align=center><img width="500" height="80" src="http://i2.tiimg.com/711106/4b1014e31ae29278.png"/><center><font color=gray size=1.5>符号检验的临界值表</font></center> </div>

<h2 id="4-两种算法的比较：推荐方法"><a href="#4-两种算法的比较：推荐方法" class="headerlink" title="4. 两种算法的比较：推荐方法"></a>4. 两种算法的比较：推荐方法</h2><p>考虑到通用性，我们需要使用非参数检验。换句话说，我们需要保证对样本的分布不做任何假设，这样更加通用。<br><strong>方法1: Wilcoxon Signed Ranks Test(WS)是配对t检验的无参数版本，</strong>同样是分析成对数据的差值是否等于0，只不过通过排名（rank）而已。换个角度看，我们也可以理解为符号检验的定量版本。我全部复现了论文里对应的这个方法，现在来详细介绍它的具体流程：</p>
<div align=center><img width="400" height="200" src="http://i1.fuimg.com/711106/07eba0f63f0978db.png"/><center><font color=gray size=1.5>两种算法在14个数据集上的准确率与排序</font></center></div>  
这里的<u>epip</u>和<u>net</u>是两个基于神经网络的分类器，第四列<u>difference</u>是两者准确率的差值, 最后一列<u>rank</u>是差值绝对值从小到大排序的序值，如果相等则取平均序数。
最上面一行，<u>R_plu</u>是第一个算法优于第二个算法对应的rank值求和，<u>R_min</u>则是第二个算法优于第一个算法对应的rank值求和，论文里把效果相同的rank值做了求和平均处理：
<center>R^+ = $\sum_{d_i>0}$rank($d_i$) + $\frac{1}{2}$$\sum_{d_i=0}$rank($d_i$)</center>
<center>R^- = $\sum_{d_i<0}$rank($d_i$) + $\frac{1}{2}$$\sum_{d_i=0}$rank($d_i$)</center> 
这里原始的统计量T=min(R^+, R^- ). 但是我们要把他化成标准的z-value形式，我们就要用公式2.1转化。首先我们要知道$\mu$=$\frac{1}{4}$N(N+1), 因为原假设是两个算法性能相同，那么A优于B和B优于A的概率应当是一样的，所以R^+ 和R^- 应当是趋于总数据集个数的序值求和的一半。对应的可以推导出$\frac{\sigma}{\sqrt{n}}$=$\sqrt{\frac{1}{24}N(N+1)(2N+1)}$  因此我们的z-value计算可以写成： 
<center>$z=\frac{T-\frac{1}{4}N(N+1)}{\sqrt{\frac{1}{24}N(N+1)(2N+1)}}\tag{3.1}$</center>  
z-value服从N(0,1).所以我们又可以计算出$\mu$左右两侧95%置信区间[$\mu$-1.96$\frac{\sigma}{\sqrt{n}}$, $\mu$+1.96$\frac{\sigma}{\sqrt{n}}$], 分别是21和96，也就是说如果T小于21或者大于96，我们就拒绝原假设。另外，我们上面还说了使用p-value来决策，我们将z-value代入相应分布的临界值表，计算相应的p-value，然后和自己心目中的置信水平比较，例如置信水平是95%，那么如果p-value小于0.05则拒绝原假设。所以在上图的例子中，我们得出的结论是epip明显优于net。  
该方法的优点如下： 
* 无参数，不要求样本符合正态分布  
* 符合数据相称性，虽然是定性的（与配对t检验相比）
* 有一定的定量特性，即较大的差别对于最终结果影响更大（与符号检验相比）

<p><strong>方法2：Mann Whitney U test</strong>(MW)和WS一样，都是无参数的且研究排名的检验方法。MW有以下特性：</p>
<ul>
<li>可以用来检测不同大小的样本，举例A算法在8个数据集上的表现 vs B算法在10个数据集上的表现。</li>
<li>对于测量方法的假设是：独立测量，这与我们的情况不符。<br>换句话说，MW是当样本量不同时才建议勉强试一试。  </li>
</ul>
<h2 id="5-多种算法间的比较：不恰当的方法"><a href="#5-多种算法间的比较：不恰当的方法" class="headerlink" title="5. 多种算法间的比较：不恰当的方法"></a>5. 多种算法间的比较：不恰当的方法</h2><div align=center><img width="400" height="200" src="http://i2.tiimg.com/711106/4a91dfbd837638b9.png"/><center><font color=gray size=1.5>四种算法在14个数据集上的准确率与排序</font></center></div>  
**不恰当方法1**：一种看法是，我们是否可以把两个算法的对比推广到多个算法上。这是一个经典的多元假设问题，这种穷举法一般都假设了不同对比之间的独立性，一般都不符合现实，我在此就不赘述了。  
**不恰当方法2:** repeated measures ANOVA是经典的统计学方法，用来进行多样本间的比较，可以看作是t检验的多元推广。ANOVA不适合对比算法表现的原因如下：
* 对样本分布有正态假设，然而不同数据集上的准确度往往不符合这个假设。  
* 不同样本有相同的总体方差。
不幸的是，我们要对比的算法表现不符合这个情况。

<h2 id="6-多种算法间的比较：推荐方法"><a href="#6-多种算法间的比较：推荐方法" class="headerlink" title="6. 多种算法间的比较：推荐方法"></a>6. 多种算法间的比较：推荐方法</h2><p><strong>方法1</strong><br>我们需要找到一种方法同时解决第五部分中提到的问题，这个方法需要：</p>
<ul>
<li>非参数，不对数据的分布做出假设。</li>
<li>不需要，或者尽量不依赖，或者可以自动修正两两对比所带来的误差。<br>Demsar^[1] 推荐了非参数的多元假设检验Friedman test。 Friedman也是一种建立在排名（rank）上的检验，它假设所有样本的排序均值想等。这个方法我也完全复现了。我们下面来讲一下他的具体流程。根据上图，矩阵里数值是准确度，旁边的括号里的值是该算法在当前数据集上和其他算法比较的排名，准确度最高的排第一。最下面一行<u>average rank</u>是每个算法在不同数据集上排名的平均值$R_i$。$R_i$服从N（$\mu$,$\sigma^2$）,其中$\mu$=$\frac{k+1}{2}$, $\sigma^2$=$\frac{k^2 -1}{12}$. 所以$\sum_{i}R_i^2$服从$\chi^2$分布。对应的统计量q-value可以写成：<center>$\chi^2=\frac{12N}{k(k+1)}[\sum_{i}R_i^2-\frac{k(k+1)^2}{4}]\tag{3.2}$</center>   
其中N代表数据集的数量，k代表算法的数量。按公式3.2计算出标准化的q-value后，带入对应$\chi^2$分布的临界值表计算p-value，方法同上，判断是否拒绝原假设。（原假设是所有算法性能相同）  
假设我们通过Friedman test 发现有统计学显著（p<0.05）,那么我们还需要继续做事后分析（post-hoc）。换句话说，  Friedman test只能告诉我们算法间是否有显著差异，而不能告诉我们到底哪些算法间有性能差异。想要定位具体的差异算法，还需要进行post-hoc分析。  
Friedman test一般配套的post-hoc是Nemenyi test，Nemenyi test可以指出两两之间是否存在显著差异。具体步骤，计算出设定好显著水平的q-value，q-value是指Nemenyi  test对应的临界值表：  
<div align=center><img width="500" height="100" src="http://i2.tiimg.com/711106/cdb90d693cb3fc3b.png"/></div>   
然后带入下面的公式计算Critical Difference:  
<center>$CD=q_\alpha\sqrt{\frac{k(k+1)}{6N}}\tag{3.3}$</center>  
这里CD可以理解为一个差距的临界值，如果两个算法的平均排序值相差大于CD，那么在当前显著水平下，性能就是显著不同的。我对论文中的表现方式稍加做了一些修改，如下图：  
<div align=center><img width="400" height="250" src="http://i2.tiimg.com/711106/940d7aa866cc083d.png"/><center><font color=gray size=1.5>Nemenyi test visualization</font></center></div>   
图中清晰地表现出，在每对算法在哪种显著水平下有显著差异。另一个值得一提的是，即使Friedman证明算法性能有显著不同，Nemenyi不一定会说明到底是哪些算法间不同，原因是Nemenyi比Friedman要弱（weak）,所以在实际场景中我采用的方法是对关注的算法再进行成对两两比较，使用WS进一步确认。  

</li>
</ul>
<p><strong>方法2</strong>：和两两对比一样，在多个样本对比时也有一些特定情况导致我们不能使用Friedman-Nemenyi。另一个或许可以值得一试的无参数方法是Kruskal Wallis test搭配Dunn’s test。这种方法的特点是：</p>
<ul>
<li>可以用来检验不同大小的样本。</li>
<li>对于测量方法的假设是：独立测量。  </li>
</ul>
<p>如果我们只有一个数据，并从数据中采样（sample）得到了很多相关的测试集1,2,3…n,并用于测试不同的算法。</p>
<ul>
<li>算法A: 测试集1，2</li>
<li>算法B：测试集3,4,5,6</li>
<li>算法N…</li>
<li>在这种情况下，我们可以用Mann Whitney Utest对比两种算法，Kruskal-Dunn对比多种算法。而且值得注意的是，这种情况常见于人工合成的数据，比如高斯分布中采样得到的数据。因此，要特别分析数据的测量方式，再决定如何评估。   <h1 id="假设检验的局限"><a href="#假设检验的局限" class="headerlink" title="假设检验的局限"></a>假设检验的局限</h1><h2 id="1-为什么做机器学习的很少做假设检验"><a href="#1-为什么做机器学习的很少做假设检验" class="headerlink" title="1.为什么做机器学习的很少做假设检验"></a>1.为什么做机器学习的很少做假设检验</h2>抛开假设检验，其实日常看到的大部分机器学习论文的实验部分都是这样一个套路：</li>
</ul>
<blockquote>
<p><font color=gray size=2.5>在 XXX benchmark dataset上，本文提出的方法比其他baseline超出了1个点or更多， 达到了新的SOTA，证明了本文提出的XXX模型/算法/机制的有效性。</font></p>
</blockquote>
<p>这个套路简单直接，只要能刷新SOTA就又能美滋滋地搞一篇论文。但如果投稿时遇上了统计出身的审稿人，很可能就会出现这种情况：</p>
<blockquote>
<p><font color=gray size=2.5>4. A visual analysis is interesting and, in this case, Figure 2 and 3 are interesting to the complete understanding of the behavior of the proposed method. However, <u>a statistical analysis must be performed</u>, in order to provide a theoretical basis to the obtained results. Having said this, I would suggest the use of a  statistical test to assess the obtained results of all techniques.</font>  </p>
</blockquote>
<p>为什么效果好还不够呢？ 这是因为预测结果有一定的随机性，它可能是集“天时地利人和”才得出的来的（也即大家戏称的“炼丹”）。如果只给出一个实验结果，我们并不能完全信任提出的模型更好。<br>那么为什么近年来很多机器学习的论文都没有用假设检验呢？<br>1） 首先， 这个圈子里有统计背景的研究者占比减少了，特别是近些年随着深度学习的兴起，以及圈子门槛的降低，接触过传统的统计学习的研究者很少，CS背景的研究者如果没有接受过相关的训练，写论文时就不会有意识地使用统计里的工具了。<br>2） 可用的数据越来越多，以往一个数据集里是几百条数据，现在动辄上万甚至百万。如果我们关心的是两个方法在总体分布上的孰优孰劣，那么对于大型数据集来说，我们一般默认数据有足够的代表性。在数据集上表现更好，那应该在总体分布上也会表现更好。当然，这种直觉未必正确，因为数据的收集方式、采样方式等等都会带来巨大的影响；<br>那到底机器学习研究里要不要做假设检验呢？我的看法是：</p>
<ul>
<li>如果是偏向理论的传统机器学习，那还是按传统的来，该做就做。</li>
<li>如果是做偏向应用的，用的是大型公开数据集，那么我觉得不是一定要做。发论文做实验往往也不是只有对比实验，还有消融实验、超参数敏感度分析、案例分析等等。这些实验同样提供了很多有价值的信息。  </li>
</ul>
<h2 id="2-局限性"><a href="#2-局限性" class="headerlink" title="2. 局限性"></a>2. 局限性</h2><p>假设检验本身的局限性我认为主要有五点：</p>
<ol>
<li>假设检验本身不等价于决策，它只为我们进行决策提供一个额外的信息。假设检验建立在概率的基础上，本身也有不确定性，我们不能完全信任假设检验的结果； </li>
<li>假设检验只告诉我们差异是否显著，但无法告诉我们差异从何而来，原因是什么。  </li>
<li>假设检验更侧重于避免Type I error, 但现实中很多场景下Type I error和Type II error是同等重要的。比如对比两重要的治病效果，我们当然不希望偏颇任意一种药；</li>
<li>假设检验只有两种结果，要么拒绝原假设，要么没有足够证据拒绝原假设（不等于接受原假设），但现实中可能会有更多结果分支；</li>
<li>假设检验仅基于手头上的数据，如果我们之前做过什么实验，或者有一些相关的证据，我们会希望能充分利用上，但假设检验没办法把这些信息结合起来；<br>总的来说，统计上的显著不等于实际上的显著。      </li>
</ol>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol>
<li>Demsar, J., 2006. Statistical comparisons of classifiers over multiple data sets. <em>Journal of Machine learning research, 7(Jan), pp.1-30.</em></li>
</ol>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Statistic-Inference/" rel="tag"># Statistic Inference</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/02/28/Introduction-of-Causal-Inference/" rel="next" title="Introduction of Causal Inference">
                <i class="fa fa-chevron-left"></i> Introduction of Causal Inference
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://www.qqtouxiang.com/d/file/tupian/mx/20170713/jitdbe00jpfpd.jpg"
                alt="Shawn_Song" />
            
              <p class="site-author-name" itemprop="name">Shawn_Song</p>
              <p class="site-description motion-element" itemprop="description">A way of self-cultivation of a young data scientist</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7Cedit">
              
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/Shawntl" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="zheweisong@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#写作背景"><span class="nav-number">1.</span> <span class="nav-text">写作背景</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#中心极限定理"><span class="nav-number">2.</span> <span class="nav-text">中心极限定理</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#假设检验的流程"><span class="nav-number">3.</span> <span class="nav-text">假设检验的流程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#假设检验的流程可以归纳如下："><span class="nav-number">3.1.</span> <span class="nav-text">假设检验的流程可以归纳如下：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-为什么需要对比算法性能？"><span class="nav-number">3.2.</span> <span class="nav-text">1. 为什么需要对比算法性能？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-评估算法中的陷阱"><span class="nav-number">3.3.</span> <span class="nav-text">2. 评估算法中的陷阱</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-两种算法间的比较：-不恰当方法"><span class="nav-number">3.4.</span> <span class="nav-text">3. 两种算法间的比较： 不恰当方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-两种算法的比较：推荐方法"><span class="nav-number">3.5.</span> <span class="nav-text">4. 两种算法的比较：推荐方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-多种算法间的比较：不恰当的方法"><span class="nav-number">3.6.</span> <span class="nav-text">5. 多种算法间的比较：不恰当的方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-多种算法间的比较：推荐方法"><span class="nav-number">3.7.</span> <span class="nav-text">6. 多种算法间的比较：推荐方法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#假设检验的局限"><span class="nav-number">4.</span> <span class="nav-text">假设检验的局限</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-为什么做机器学习的很少做假设检验"><span class="nav-number">4.1.</span> <span class="nav-text">1.为什么做机器学习的很少做假设检验</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-局限性"><span class="nav-number">4.2.</span> <span class="nav-text">2. 局限性</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#参考资料"><span class="nav-number">5.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Shawn_Song</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  


  

  

</body>
</html>
